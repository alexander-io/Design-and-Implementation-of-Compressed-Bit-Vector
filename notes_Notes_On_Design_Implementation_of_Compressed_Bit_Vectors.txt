Research Article Title :
  Notes on Design and Implementation of Compressed Bit Vectors

Authors :
  Kesheng Wu, Ekow J. Otoo, Arie Shoshani, Henrik Nordberg

Date :
  September 27, 2001

Abstract :

  bitmap based indexing schemes work effectively in database applications

  compression schemes can be use to further improve their ^ effectiveness

  compression schemes can reduce the index size without increasing query processing time

  a bitmap index is stored as a collection of bitmaps
  the most frequent operations on these bitmaps are bitwise logical operations (AND, OR, NOT, XOR, SHIFT)

  to achieve this, reducing the size of indices is essential
  we want to be able to perform logical operations on the compressed bitmaps efficiently

  compression schemes (such as gzip) are effective in reducing the storage requirement, but don't support faster bitwise logical operations

  most specialized bitmap compression schemes are byte based, i.e., they access memory one byte at a time, and can not take full advantage of today's computing hardware that supports fast word operations.

  the paper introduces a number of word-based compression schemes with the expectation that they may support faster logical operations than the byte-based schemes

  word based schemes can be dozens of times faster than the byte based ones

  in many cases, word based compression bitmaps also perform bitwise logical operations faster than the uncompressed bitmaps

  Q&A for Abstract :
    what is the paper about?
    it is a study on a number of generic lossless compression algorithms and a number of specialized compression schemes
    it also serves as an introduction to a number of word-based compression schemes that may be preferable to byte-based compression schemes when run on modern hardware
    using compression algorithms and compression schemes, we are able to reduce the index size of a database without increasing query processing time
    the paper focuses on the type of compressed bit vectors that can support 'direct logical operations' which extinguish the necessity to uncompress bit vectors in order to perform logical operations (<- this tid-bit is found in the Introduction)

Part 1, Introduction :
  the term 'bitmap index' is used to refer to a broad category of indexing schemes that store their indices as bit sequences and use bitwise logical operations as athe primary means to extract answers from the indices

  'bitmap index' is effective for data warehouses and similar applications where the databases are read-mostly and the user queries usually involve more than one attribute


  the bitmap index allows the translation of queries...
    for example (using Figure 1), the query "R = B AND X < 4" can be translated to the following logical operations among 3 bit-sequences "b2 AND (b5 OR b6)"
    where :
      b2 : 01000010
      b5 : 00001010
      b6 : 10000000

    and the result of the aforementioned bitwise operations is a bit-sequence storing the result, in the above case 00000010 = result
    lastly, "if the ith bit of the result is 1, then the ith tuple of the database qualifies the query"

  there are well studied general purpose compression algorithms such as gzip and bzip2...
  ... however, these generic compression schemes are effective in compressing the bit sequences, but bitwise logical operations on the compressed bit sequences are much slower than operating on their uncompressed versions.

  since the logical operations are the crucial operations during query processing, the logical operations need to be as fast as possible.
  ^ to achieve this goal, we need to use compression schemes that support fast bitwise logical operations

  the computer data structure used to represent bit sequences is called a bit-vector (this term is used rather than bitmap to emphasis that the logical operations are a crucial part of the data structure)

  compression :
    a straightforward way of representing such a bit sequence is to use one bit of computer memory to represent one bit of the bit sequence, this is called 'literal bit vector'
    a simple idea of compressing a bit sequences is to break into a series of smaller sequences of consecutive identical bits, this is referred to as a 'fill'
    since each fill can be recorded with a counter representing its length plus one bit indicating the actual bit values, this representation may use less apce compared to the literal version, this is known as 'run-length encoding'
    if a run length is long enough, then the run-length encoding will use less space than the literal representation
    when performing a logical operation, working directly with the counters ensures that a minimum amount of computer memory is used to represent the operands and the result.
    compared to the alternative of decompressing the operands first then operating on the uncompressed bit vectors, operating directly on the compressed data needs less time because it avoids producing the intermediate uncompressed versions,
    this paper focuses on the type of compressed bit vectors that can support this type of direct logical operations

  the remainder of the paper will present 3 types of bit-vector schemes, namely, the literal scheme, byte based scheme, and word based scheme

Part 2, Literal Bit Vector and Generic Compression Schemes
  this section describes the literal version of the bit vector and explores how to use the generic lossless compression programs to reduce the size of the file

  remember, the literal version of the bit vector uses one bit of of computer memory to represent each of the bit sequences

  in a typical computer memory system, bits are organized into bytes and words...
  ... though a word typically contains several bytes most likely it takes the same amount of work to access either a word or a byte...
  ... in fact it may be slower to access a byte than to access a word, this is because most CPUs can only operate on data one word at a time

  the following algorithm describes how a bitwise logical operation can be performed.
  the subscripting operator [] and functions size(), back(), and push_back() are part of STL vector container.

  algorithm no.1, to perform a bitwise logical operation between two literal bit vectors x and y, and store the result in z.
  symbol ~ (tilde) denotes one of the three logical operations, AND, OR, or XOR

    for(i=0; i < x.vec.size();++i) {
      z.vec[i] = x.vec[i] ~ y.vec[i];
    }
    z.active.nbits = x.active.nbits;

    z.active.value = x.active.value ~ y.active.value;

    class activeWord {
      unsigned value;     // literal value of the active word
      unsigned nbits;     // number of bits in the active word
    };

    class literalBitVector {
      std::vector<unsigned> vec;    	A  // list of regular words
      activeWord active;              // the active word
    }




    table no.1 - performance information of the literal (lit) version of bit vector

    	no. of bits 		10^7		10^8		10^9
    	no. of byte 		1.25*10^6	1.25*10^7	1.25^10^8		 
    		 
    	read only (sec)		0.020		0.195		2.00		(1) time to read a file one page at a time and discard the content, marked 'read only'			
    	read to bit vector 	0.048		0.490		4.89 		(2) time to read a file and form a bit vector from the file content, marked 'read to bit vector'
    	logical operation 	0.010		0.127		1.280		(3) time to perform a single bitwise logical operation between two bit vectors

    	table 1 contains three timing results 
    		(1) time to read a file one page at a time and discard the content, marked 'read only' 
    		(2) time to read a file and form a bit vector from the file content, marked 'read to bit vector' 
    		(3) time to perform a single bitwise logical operation between two bit vectors -> note, in this implementation, the three logical operations AND, OR and XOR, take the same amount of time
    		the timing results reported in table 1 are recored using getrusage function 	



    the logical operation time on two 10^8 bit sequences is more than 10 times that on two 10^7 bit sequences because the data involved in the shorter bit sequences can fit into the 4mb data cache of the processor, but not the larger ones

    when used to represent the bitmap indices, these bit vectors are much more likely to be read than be written

    reading a file and forming a bit vector takes about twice as long as simply reading the file because we need to copy the content into the vector container

    replacing the stl vector with a custom data structure that avoids this copying would remove most of the over head in forming the literal bit vector

    "Ideally, a good compressed bit vector should use less memory (no. of bytes) and perform logical operations in less time than this literal scheme" - page 6

    three compression routines that are potential candidates for use :
    	gzip
    		this is one of the most popular compression utilities
    		it uses lempel-ziv coding (lz77) which is known to be asymptotically optimal
    		it is freely available and it also comes with a set of easy to use API (zlib) for performing bitwise logical operations

    	bzip2
    		this uses borrows-wheeler text compression and huffman coding
    		its documentation claims that it is often faster than gzip and even compresses better than gzip in many cases
    		it offers similar API as zlib

    	lzop
    		this one implements a modified version of the lempel-ziv scheme
    		the decompresser is very efficient and it is able to achieve a significant fraction of the speed of memcpy() function
    		this makes it particularly attractive because the decompresser is likely to be used more often than the compressor

    "When the bit density is low, the compression programs are very effective; the compressed files are much smaller than uncompressed files." - page 6

    as the bit density increases, compression becomes less effective


    figure 5 (page 8) and table 2 (page 9) show timing results of two ways of processing the compressed bit vector files and performing bitwise logical operations on them
    'two step approach', the first approach does this in two steps :
    	(1) read two files containing two operands of the logical operation and decompress the data into two literal bit vectors
    	(2) perform the logical operations on these two bit vectors

    the second approach reads the two files one piece at a time using zlib functions, perform the bitwise operation on the portion of data and store the results in a bit vector 
    this is marked as the 'one-step' approach in figure 5 and table 2

    in some cases, it may be useful to use the two step approach and store the bit vectors in memory so that the later operations do not need to read the files again


	QUESTION
	    (page 4) why is the following suggestion true?  'though a word typically contains several bytes, most likely it takes the same amount of work to access either a word or a byte'
	    what is an STL vector container? [resource no.27]


Part 3, Byte Based Schemes
	when used to store images, the smallest unit of data accessed by most image formats is a byte
	for this reason, most existing bitmap compression schemes are byte based


	3.1 PackBits (PAC)

		this is a simple scheme designed for compressing bitmap images
		the PackBit scheme first divides a long bit sequence into bytes and then groups the consecutive bytes into two types of runs :
			literal runs
				a literal run can have 0-127 bytes of arbitrary values
				a header byte is used to indicate the run length, i.e., the number of bytes in the run

			fill runs
				a fill run can represent 2-129 bytes of the same value 
				it is an unsigned integer that is equal to the run plus 126

		this scheme does not require all the bits in the fill to be the same, only that all the bytes by the same
		because each run of PackBits represents multiple of 8 bits, we say this scheme is byte aligned

		Algorithm 2
			to append a literal byte to a list of regular encoded bytes stored in a vector container called vec
			the active byte is used as a place holder for this literal byte
			when the bit vector is empty, the vector container vec is empty {
				set the first byte in vec to be 1 (vec.push_back(1))
				the second byte to be the value of the active byte (vec.push_back(active.value))
				lastHeader = 0
			} otherwise {
				// see page 7 for algorithm 2
			}


		analysis of PackBits (PAC)
			if all bytes are the same, this scheme uses two bytes to represent every 129 bytes
			the best case compression ratio is 0.0155
			if all bytes are literal bytes, it uses 128 bytes to represent every 127 literal bytes, a 0.8% overhead
			if a bit sequence consists of two bytes that are the same followed by a third byte that is different from the first two, this scheme needs for bytes to represent these three bytes -> this worst case overhead is 33%


		Algorithm 3
			given two packbits bit vectors x and y, perform an arbitrary bitwise logical operation (denoted ~) to produce a bit vector z

			run xrun, yrun
			xrun.it = x.vec.begin()
			yrun.it = v.vec.begin()
			// ... see page 11 for algorithm 3 

	3.2 Byte-aligned Bitmap Code (BBC)
		the original version of this scheme was invented by G.Antoshenkov

